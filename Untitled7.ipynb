{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNsmK+E1ZJkGh81nLjUqphE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apoorvxgoyalx/Blog_Website/blob/main/Untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTlcdFQJZWoX",
        "outputId": "87ca678a-010f-49dc-f516-d1ccca3a2723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.80)\n",
            "Requirement already satisfied: supervision in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (2.0.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from supervision) (1.3.1)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from supervision) (0.7.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install ultralytics supervision shapely matplotlib pandas numpy opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!ls '/content/drive/My Drive'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTlO4poOaYbN",
        "outputId": "f2fc6f5c-f74e-4498-f077-b683b90ae005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "'10th marksheet.pdf'\n",
            "'28 Apoorv Goyal.pdf'\n",
            "'Adobe Scan Nov 14, 2022.pdf'\n",
            "'Adobe Scan Oct 12, 2022.gdoc'\n",
            "'Adobe Scan Oct 12, 2022.pdf'\n",
            "'Amazon ML Challenge.gdoc'\n",
            "'Apoorv Goyal 105.pdf'\n",
            "'Apoorv Goyal 106.pdf'\n",
            "'Apoorv Goyal 107 (10).pdf'\n",
            "'Apoorv Goyal 107 (11).pdf'\n",
            "'Apoorv Goyal 107 (12).pdf'\n",
            "'Apoorv Goyal 107 (13).pdf'\n",
            "'Apoorv Goyal 107 (14).pdf'\n",
            "'Apoorv Goyal 107 (1).pdf'\n",
            "'Apoorv Goyal 107 (2).pdf'\n",
            "'Apoorv Goyal 107 (3).pdf'\n",
            "'Apoorv Goyal 107 (4).pdf'\n",
            "'Apoorv Goyal 107 (5).pdf'\n",
            "'Apoorv Goyal 107 (6).pdf'\n",
            "'Apoorv Goyal 107 (7).pdf'\n",
            "'Apoorv Goyal 107 (8).pdf'\n",
            "'Apoorv Goyal 107 (9).pdf'\n",
            "'Apoorv Goyal 107.pdf'\n",
            "'Apoorv Goyal - Btech Cst'\n",
            "'apoorv goyal cst 1st year photos'\n",
            " Apoorv_Goyal_FDS.zip\n",
            "'Apoorv Goyal resume 100 (1).pdf'\n",
            "'Apoorv Goyal resume 100 (2).pdf'\n",
            "'Apoorv Goyal resume 100.pdf'\n",
            " apoorvgoyalresume..pdf\n",
            " apoorvgoyalresume.pdf\n",
            "'Apoorv Goyal Resume.pdf'\n",
            "'Apoorv Goyal resume up.pdf'\n",
            "'Business process manual.gdoc'\n",
            " Classroom\n",
            "'CNS PROJECT.gdoc'\n",
            "'Colab Notebooks'\n",
            "'Copy of image_chips_native-20250212T103727Z-001.zip'\n",
            " DB0DF3AC-423D-4A7A-86AB-9488A717219A.jpeg\n",
            "'Design Document.gdoc'\n",
            "'drdo certificate.pdf'\n",
            "'dslr pics'\n",
            "'Fest '\n",
            "'Humayun edit'\n",
            "'HWM1111 - MAVERICKS.pdf'\n",
            " IITG\n",
            "'IMG_3976 (1).png'\n",
            " IMG_3976.png\n",
            "'IMG_7311 (1).png'\n",
            "'IMG_7311 (2).png'\n",
            " IMG_7311.png\n",
            " INDEX.gdoc\n",
            " in.gov.cbse-HSCER-146023142022.pdf\n",
            " Introduction.gdoc\n",
            " LISTINGWEBAPP\n",
            "'marksheet sem1 (1).pdf'\n",
            "'marksheet sem1.pdf'\n",
            "'marksheet sem2 (1).pdf'\n",
            "'marksheet sem2.pdf'\n",
            "'marksheet sem3 (1).pdf'\n",
            "'marksheet sem3.pdf'\n",
            " Mavericks_ppt_samples.pdf\n",
            "'My Merged Document.gdoc'\n",
            " output.zip\n",
            "'Photo from Apoorv Goyal.JPEG'\n",
            "'Requirement Analysis final.pdf'\n",
            "'Requirement Analysis.gdoc'\n",
            " resume1word.docx\n",
            " Resume.gdoc\n",
            "'rules and regulations.gdoc'\n",
            "'Sanyyam Gupta_240705_183749.docx'\n",
            "'Sanyyam Gupta_240705_183749.pdf'\n",
            "'Screenshot 2024-09-08 at 12.01.54 PM.png'\n",
            " SIH2024_IDEA_Presentation_PDF.pdf\n",
            " SIHTeamDetails.pdf\n",
            " srip\n",
            " srip_task\n",
            " task1.py\n",
            "'Testing Section.gdoc'\n",
            "'Untitled document (1).gdoc'\n",
            "'Untitled document (2).gdoc'\n",
            "'Untitled document (3).gdoc'\n",
            "'Untitled document (4).gdoc'\n",
            "'Untitled document.gdoc'\n",
            "'Untitled folder'\n",
            "'Untitled spreadsheet.gsheet'\n",
            " xampp-windows-x64-8.2.12-0-VS16-installer.exe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/My Drive'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vowSoGub8yT",
        "outputId": "726af4d8-57f2-4f05-b876-d362230341ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'10th marksheet.pdf'\n",
            "'28 Apoorv Goyal.pdf'\n",
            "'Adobe Scan Nov 14, 2022.pdf'\n",
            "'Adobe Scan Oct 12, 2022.gdoc'\n",
            "'Adobe Scan Oct 12, 2022.pdf'\n",
            "'Amazon ML Challenge.gdoc'\n",
            "'Apoorv Goyal 105.pdf'\n",
            "'Apoorv Goyal 106.pdf'\n",
            "'Apoorv Goyal 107 (10).pdf'\n",
            "'Apoorv Goyal 107 (11).pdf'\n",
            "'Apoorv Goyal 107 (12).pdf'\n",
            "'Apoorv Goyal 107 (13).pdf'\n",
            "'Apoorv Goyal 107 (14).pdf'\n",
            "'Apoorv Goyal 107 (1).pdf'\n",
            "'Apoorv Goyal 107 (2).pdf'\n",
            "'Apoorv Goyal 107 (3).pdf'\n",
            "'Apoorv Goyal 107 (4).pdf'\n",
            "'Apoorv Goyal 107 (5).pdf'\n",
            "'Apoorv Goyal 107 (6).pdf'\n",
            "'Apoorv Goyal 107 (7).pdf'\n",
            "'Apoorv Goyal 107 (8).pdf'\n",
            "'Apoorv Goyal 107 (9).pdf'\n",
            "'Apoorv Goyal 107.pdf'\n",
            "'Apoorv Goyal - Btech Cst'\n",
            "'apoorv goyal cst 1st year photos'\n",
            " Apoorv_Goyal_FDS.zip\n",
            "'Apoorv Goyal resume 100 (1).pdf'\n",
            "'Apoorv Goyal resume 100 (2).pdf'\n",
            "'Apoorv Goyal resume 100.pdf'\n",
            " apoorvgoyalresume..pdf\n",
            " apoorvgoyalresume.pdf\n",
            "'Apoorv Goyal Resume.pdf'\n",
            "'Apoorv Goyal resume up.pdf'\n",
            "'Business process manual.gdoc'\n",
            " Classroom\n",
            "'CNS PROJECT.gdoc'\n",
            "'Colab Notebooks'\n",
            "'Copy of image_chips_native-20250212T103727Z-001.zip'\n",
            " DB0DF3AC-423D-4A7A-86AB-9488A717219A.jpeg\n",
            "'Design Document.gdoc'\n",
            "'drdo certificate.pdf'\n",
            "'dslr pics'\n",
            "'Fest '\n",
            "'Humayun edit'\n",
            "'HWM1111 - MAVERICKS.pdf'\n",
            " IITG\n",
            "'IMG_3976 (1).png'\n",
            " IMG_3976.png\n",
            "'IMG_7311 (1).png'\n",
            "'IMG_7311 (2).png'\n",
            " IMG_7311.png\n",
            " INDEX.gdoc\n",
            " in.gov.cbse-HSCER-146023142022.pdf\n",
            " Introduction.gdoc\n",
            " LISTINGWEBAPP\n",
            "'marksheet sem1 (1).pdf'\n",
            "'marksheet sem1.pdf'\n",
            "'marksheet sem2 (1).pdf'\n",
            "'marksheet sem2.pdf'\n",
            "'marksheet sem3 (1).pdf'\n",
            "'marksheet sem3.pdf'\n",
            " Mavericks_ppt_samples.pdf\n",
            "'My Merged Document.gdoc'\n",
            " output.zip\n",
            "'Photo from Apoorv Goyal.JPEG'\n",
            "'Requirement Analysis final.pdf'\n",
            "'Requirement Analysis.gdoc'\n",
            " resume1word.docx\n",
            " Resume.gdoc\n",
            "'rules and regulations.gdoc'\n",
            "'Sanyyam Gupta_240705_183749.docx'\n",
            "'Sanyyam Gupta_240705_183749.pdf'\n",
            "'Screenshot 2024-09-08 at 12.01.54 PM.png'\n",
            " SIH2024_IDEA_Presentation_PDF.pdf\n",
            " SIHTeamDetails.pdf\n",
            " srip\n",
            " srip_task\n",
            " task1.py\n",
            "'Testing Section.gdoc'\n",
            "'Untitled document (1).gdoc'\n",
            "'Untitled document (2).gdoc'\n",
            "'Untitled document (3).gdoc'\n",
            "'Untitled document (4).gdoc'\n",
            "'Untitled document.gdoc'\n",
            "'Untitled folder'\n",
            "'Untitled spreadsheet.gsheet'\n",
            " xampp-windows-x64-8.2.12-0-VS16-installer.exe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "DATASET_PATH = '/content/drive/My Drive/srip_task'\n",
        "\n",
        "\n",
        "!mkdir -p /content/solar_panel_detection\n",
        "!mkdir -p /content/solar_panel_detection/data\n",
        "\n",
        "print(\"Contents of dataset folder:\")\n",
        "!ls \"{DATASET_PATH}\"\n",
        "\n",
        "\n",
        "!mkdir -p /content/solar_panel_detection/data/images\n",
        "!mkdir -p /content/solar_panel_detection/data/labels\n",
        "\n",
        "\n",
        "IMAGE_ZIP = os.path.join(DATASET_PATH, 'image_chips_native-20250212T103727Z-001.zip')\n",
        "!unzip -q \"{IMAGE_ZIP}\" -d /content/solar_panel_detection/data/images\n",
        "\n",
        "LABELS_ZIP = os.path.join(DATASET_PATH, 'labels-20250212T103318Z-001.zip')\n",
        "!unzip -q \"{LABELS_ZIP}\" -d /content/solar_panel_detection/data/labels\n",
        "\n",
        "print(\"\\nExtracted image contents:\")\n",
        "!ls /content/solar_panel_detection/data/images | head -5\n",
        "\n",
        "print(\"\\nExtracted label contents:\")\n",
        "!ls /content/solar_panel_detection/data/labels | head -5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYWWEvo2apuU",
        "outputId": "46bb18ac-8760-465d-94b3-5a8e4ffd86bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of dataset folder:\n",
            "image_chips_native-20250212T103727Z-001.zip  labels-20250212T103318Z-001.zip\n",
            "replace /content/solar_panel_detection/data/images/image_chips_native/solarpanels_native_2__x0_8521_y0_3953_dxdy_416.tif? [y]es, [n]o, [A]ll, [N]one, [r]ename: replace /content/solar_panel_detection/data/labels/labels/labels_hd/solarpanels_hd_1__x0_15750_y0_16870_dxdy_832.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import shutil\n",
        "\n",
        "\n",
        "EXTRACTED_IMAGES_PATH = '/content/solar_panel_detection/data/images'\n",
        "EXTRACTED_LABELS_PATH = '/content/solar_panel_detection/data/labels'\n",
        "\n",
        "#  we want to use the 31 cm native resolution images (416x416)\n",
        "NATIVE_IMAGES_PATH = glob.glob(f\"{EXTRACTED_IMAGES_PATH}/*native*\")\n",
        "if NATIVE_IMAGES_PATH:\n",
        "    NATIVE_IMAGES_PATH = NATIVE_IMAGES_PATH[0]\n",
        "    print(f\"Found native images at: {NATIVE_IMAGES_PATH}\")\n",
        "\n",
        "    # check the actual structure\n",
        "    !ls \"{NATIVE_IMAGES_PATH}\" | head -5\n",
        "else:\n",
        "    print(\"Native images folder not found. Check the zip file structure.\")\n",
        "\n",
        "# we want to use the labels for native resolution\n",
        "NATIVE_LABELS_PATH = os.path.join(EXTRACTED_LABELS_PATH, 'labels/labels_native')\n",
        "if os.path.exists(NATIVE_LABELS_PATH):\n",
        "    print(f\"Found native labels at: {NATIVE_LABELS_PATH}\")\n",
        "\n",
        "    # check the actual structure\n",
        "    !ls \"{NATIVE_LABELS_PATH}\" | head -5\n",
        "else:\n",
        "    print(\"Native labels folder not found. Check the extraction process.\")\n",
        "\n",
        "# create train/val/test\n",
        "!mkdir -p /content/solar_panel_detection/data/images/train\n",
        "!mkdir -p /content/solar_panel_detection/data/images/val\n",
        "!mkdir -p /content/solar_panel_detection/data/images/test\n",
        "!mkdir -p /content/solar_panel_detection/data/labels/train\n",
        "!mkdir -p /content/solar_panel_detection/data/labels/val\n",
        "!mkdir -p /content/solar_panel_detection/data/labels/test"
      ],
      "metadata": {
        "id": "MmlpZ1uIej4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def get_image_files(dir_path):\n",
        "    return glob.glob(f\"{dir_path}/*.tif\") + glob.glob(f\"{dir_path}/*.jpg\") + glob.glob(f\"{dir_path}/*.png\")\n",
        "\n",
        "\n",
        "def read_label_file(label_path):\n",
        "    with open(label_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    boxes = []\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()\n",
        "        if len(parts) >= 5:  # category, x-center, y-center, width, height\n",
        "            category = int(parts[0])\n",
        "            x_center = float(parts[1])\n",
        "            y_center = float(parts[2])\n",
        "            width = float(parts[3])\n",
        "            height = float(parts[4])\n",
        "            boxes.append([category, x_center, y_center, width, height])\n",
        "\n",
        "    return np.array(boxes)\n",
        "\n",
        "\n",
        "image_files = get_image_files(NATIVE_IMAGES_PATH)\n",
        "\n",
        "if image_files:\n",
        "\n",
        "    random_image_path = random.choice(image_files)\n",
        "    image_name = os.path.basename(random_image_path)\n",
        "    print(f\"Selected image: {image_name}\")\n",
        "\n",
        "\n",
        "    label_name = os.path.splitext(image_name)[0] + '.txt'\n",
        "    label_path = os.path.join(NATIVE_LABELS_PATH, label_name)\n",
        "\n",
        "    if os.path.exists(label_path):\n",
        "\n",
        "        img = cv2.imread(random_image_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        height, width, _ = img.shape\n",
        "\n",
        "\n",
        "        boxes = read_label_file(label_path)\n",
        "\n",
        "\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        plt.imshow(img)\n",
        "\n",
        "\n",
        "        for box in boxes:\n",
        "            category, x_center, y_center, box_width, box_height = box\n",
        "\n",
        "\n",
        "            x1 = int((x_center - box_width/2) * width)\n",
        "            y1 = int((y_center - box_height/2) * height)\n",
        "            x2 = int((x_center + box_width/2) * width)\n",
        "            y2 = int((y_center + box_height/2) * height)\n",
        "\n",
        "\n",
        "            plt.gca().add_patch(plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
        "                                              fill=False, edgecolor='red', linewidth=2))\n",
        "\n",
        "        plt.title(f\"Image: {image_name} with bounding boxes\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"Image dimensions: {width}x{height}\")\n",
        "        print(f\"Number of bounding boxes: {len(boxes)}\")\n",
        "        print(\"Sample bounding box data (category, x_center, y_center, width, height):\")\n",
        "        if len(boxes) > 0:\n",
        "            print(boxes[0])\n",
        "    else:\n",
        "        print(f\"Corresponding label file not found: {label_path}\")\n",
        "else:\n",
        "    print(\"No image files found.\")"
      ],
      "metadata": {
        "id": "bc2cDndVevQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "\n",
        "def split_dataset(image_files, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n",
        "    \"\"\"\n",
        "    Split the dataset into train, validation, and test sets.\n",
        "    \"\"\"\n",
        "\n",
        "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-10\n",
        "\n",
        "\n",
        "    train_files, temp_files = train_test_split(image_files, train_size=train_ratio, random_state=42)\n",
        "\n",
        "    val_ratio_adjusted = val_ratio / (val_ratio + test_ratio)\n",
        "    val_files, test_files = train_test_split(temp_files, train_size=val_ratio_adjusted, random_state=42)\n",
        "\n",
        "    return train_files, val_files, test_files\n",
        "\n",
        "image_files = get_image_files(NATIVE_IMAGES_PATH)\n",
        "\n",
        "if image_files:\n",
        "    train_files, val_files, test_files = split_dataset(image_files)\n",
        "\n",
        "    print(f\"Total images: {len(image_files)}\")\n",
        "    print(f\"Training images: {len(train_files)} ({len(train_files)/len(image_files)*100:.1f}%)\")\n",
        "    print(f\"Validation images: {len(val_files)} ({len(val_files)/len(image_files)*100:.1f}%)\")\n",
        "    print(f\"Testing images: {len(test_files)} ({len(test_files)/len(image_files)*100:.1f}%)\")\n",
        "\n",
        "\n",
        "    def copy_dataset_files(file_list, destination_images, destination_labels):\n",
        "        for file_path in file_list:\n",
        "\n",
        "            image_name = os.path.basename(file_path)\n",
        "            shutil.copy(file_path, os.path.join(destination_images, image_name))\n",
        "\n",
        "            label_name = os.path.splitext(image_name)[0] + '.txt'\n",
        "            label_path = os.path.join(NATIVE_LABELS_PATH, label_name)\n",
        "            if os.path.exists(label_path):\n",
        "                shutil.copy(label_path, os.path.join(destination_labels, label_name))\n",
        "\n",
        "\n",
        "    copy_dataset_files(train_files, '/content/solar_panel_detection/data/images/train',\n",
        "                        '/content/solar_panel_detection/data/labels/train')\n",
        "\n",
        "    copy_dataset_files(val_files, '/content/solar_panel_detection/data/images/val',\n",
        "                        '/content/solar_panel_detection/data/labels/val')\n",
        "\n",
        "    copy_dataset_files(test_files, '/content/solar_panel_detection/data/images/test',\n",
        "                        '/content/solar_panel_detection/data/labels/test')\n",
        "\n",
        "\n",
        "    print(\"\\nVerifying dataset split:\")\n",
        "    print(f\"Train images: {len(os.listdir('/content/solar_panel_detection/data/images/train'))}\")\n",
        "    print(f\"Train labels: {len(os.listdir('/content/solar_panel_detection/data/labels/train'))}\")\n",
        "    print(f\"Val images: {len(os.listdir('/content/solar_panel_detection/data/images/val'))}\")\n",
        "    print(f\"Val labels: {len(os.listdir('/content/solar_panel_detection/data/labels/val'))}\")\n",
        "    print(f\"Test images: {len(os.listdir('/content/solar_panel_detection/data/images/test'))}\")\n",
        "    print(f\"Test labels: {len(os.listdir('/content/solar_panel_detection/data/labels/test'))}\")\n",
        "else:\n",
        "    print(\"No image files found. Cannot split the dataset.\")"
      ],
      "metadata": {
        "id": "6GkP3AH6ezzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_yaml_config():\n",
        "    yaml_content = \"\"\"\n",
        "# Train/val/test sets\n",
        "path: /content/solar_panel_detection/data  # dataset root dir\n",
        "train: images/train  # train images (relative to 'path')\n",
        "val: images/val  # val images (relative to 'path')\n",
        "test: images/test  # test images (relative to 'path')\n",
        "\n",
        "# Classes\n",
        "names:\n",
        "  0: solar_panel\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "    config_path = '/content/solar_panel_detection/data/solar_panel.yaml'\n",
        "    with open(config_path, 'w') as f:\n",
        "        f.write(yaml_content)\n",
        "\n",
        "    print(f\"Created YAML config file at: {config_path}\")\n",
        "\n",
        "\n",
        "create_yaml_config()"
      ],
      "metadata": {
        "id": "1TQHNB-6fCuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "\n",
        "display(Javascript('''\n",
        "function ClickConnect(){\n",
        "  console.log(\"Clicking connect button\");\n",
        "  document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}\n",
        "setInterval(ClickConnect, 60000)\n",
        "'''))"
      ],
      "metadata": {
        "id": "ajx5fXhRfFs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import ultralytics\n",
        "from ultralytics import YOLO\n",
        "import supervision as sv\n",
        "from shapely.geometry import box\n",
        "\n",
        "print(f\"Ultralytics version: {ultralytics.__version__}\")\n",
        "print(f\"Supervision version: {sv.__version__}\")\n",
        "\n",
        "\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
      ],
      "metadata": {
        "id": "gs4phZq0fIPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "data_dir = '/content/solar_panel_detection/data'\n",
        "train_dir = os.path.join(data_dir, 'images/train')\n",
        "train_labels_dir = os.path.join(data_dir, 'labels/train')\n",
        "val_dir = os.path.join(data_dir, 'images/val')\n",
        "val_labels_dir = os.path.join(data_dir, 'labels/val')\n",
        "test_dir = os.path.join(data_dir, 'images/test')\n",
        "test_labels_dir = os.path.join(data_dir, 'labels/test')\n",
        "\n",
        "def read_yolo_labels(label_path):\n",
        "    if not os.path.exists(label_path):\n",
        "        return []\n",
        "\n",
        "    with open(label_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    labels = []\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()\n",
        "        if len(parts) >= 5:  # class, x, y, width, height\n",
        "            label = {\n",
        "                'class': int(parts[0]),\n",
        "                'x_center': float(parts[1]),\n",
        "                'y_center': float(parts[2]),\n",
        "                'width': float(parts[3]),\n",
        "                'height': float(parts[4])\n",
        "            }\n",
        "            labels.append(label)\n",
        "\n",
        "    return labels\n",
        "\n",
        "\n",
        "def compute_dataset_stats(images_dir, labels_dir, img_size=416):\n",
        "    image_files = glob.glob(os.path.join(images_dir, '*.tif')) + \\\n",
        "                  glob.glob(os.path.join(images_dir, '*.jpg')) + \\\n",
        "                  glob.glob(os.path.join(images_dir, '*.png'))\n",
        "\n",
        "    total_instances = 0\n",
        "    labels_per_image = {}\n",
        "    areas = []\n",
        "\n",
        "    # calculate the ground sample distance (GSD) - 31 cm per pixel\n",
        "    gsd = 0.31  # meters per pixel\n",
        "\n",
        "    for img_path in image_files:\n",
        "\n",
        "        base_name = os.path.basename(img_path).split('.')[0]\n",
        "        label_path = os.path.join(labels_dir, f\"{base_name}.txt\")\n",
        "\n",
        "\n",
        "        labels = read_yolo_labels(label_path)\n",
        "\n",
        "\n",
        "        num_labels = len(labels)\n",
        "        total_instances += num_labels\n",
        "\n",
        "\n",
        "        if num_labels in labels_per_image:\n",
        "            labels_per_image[num_labels] += 1\n",
        "        else:\n",
        "            labels_per_image[num_labels] = 1\n",
        "\n",
        "\n",
        "        if num_labels > 0:\n",
        "            for label in labels:\n",
        "                #  normalized dimensions to pixel dimensions\n",
        "                width_pixels = label['width'] * img_size\n",
        "                height_pixels = label['height'] * img_size\n",
        "\n",
        "                # meters using the GSD\n",
        "                width_meters = width_pixels * gsd\n",
        "                height_meters = height_pixels * gsd\n",
        "\n",
        "                # area in square meters\n",
        "                area_meters = width_meters * height_meters\n",
        "                areas.append(area_meters)\n",
        "\n",
        "    return total_instances, labels_per_image, areas\n",
        "\n",
        "# statistics for each dataset split\n",
        "print(\"Analyzing training set...\")\n",
        "train_instances, train_labels_dist, train_areas = compute_dataset_stats(train_dir, train_labels_dir)\n",
        "print(\"Analyzing validation set...\")\n",
        "val_instances, val_labels_dist, val_areas = compute_dataset_stats(val_dir, val_labels_dir)\n",
        "print(\"Analyzing test set...\")\n",
        "test_instances, test_labels_dist, test_areas = compute_dataset_stats(test_dir, test_labels_dir)\n",
        "\n",
        "# combine statistics\n",
        "total_instances = train_instances + val_instances + test_instances\n",
        "all_areas = train_areas + val_areas + test_areas\n",
        "\n",
        "# combine label distributions\n",
        "all_labels_dist = {}\n",
        "for dist in [train_labels_dist, val_labels_dist, test_labels_dist]:\n",
        "    for num_labels, count in dist.items():\n",
        "        if num_labels in all_labels_dist:\n",
        "            all_labels_dist[num_labels] += count\n",
        "        else:\n",
        "            all_labels_dist[num_labels] = count\n",
        "\n",
        "sorted_labels_dist = dict(sorted(all_labels_dist.items()))\n",
        "\n",
        "print(f\"\\n1. Total solar panel instances in the dataset: {total_instances}\")\n",
        "\n",
        "print(\"\\n2. Label count distribution (labels per image):\")\n",
        "for num_labels, count in sorted_labels_dist.items():\n",
        "    print(f\"   {count} images have {num_labels} labels\")\n",
        "\n",
        "if all_areas:\n",
        "    mean_area = np.mean(all_areas)\n",
        "    std_area = np.std(all_areas)\n",
        "    min_area = np.min(all_areas)\n",
        "    max_area = np.max(all_areas)\n",
        "    median_area = np.median(all_areas)\n",
        "\n",
        "    print(\"\\n3. Solar panel area statistics (in square meters):\")\n",
        "    print(f\"   Method: Calculated from bounding box dimensions using GSD of 31 cm per pixel\")\n",
        "    print(f\"   Mean area: {mean_area:.2f} m²\")\n",
        "    print(f\"   Median area: {median_area:.2f} m²\")\n",
        "    print(f\"   Standard deviation: {std_area:.2f} m²\")\n",
        "    print(f\"   Min area: {min_area:.2f} m²\")\n",
        "    print(f\"   Max area: {max_area:.2f} m²\")\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.histplot(all_areas, bins=30, kde=True, color='skyblue')\n",
        "    plt.axvline(mean_area, color='red', linestyle='--', label=f'Mean: {mean_area:.2f} m²')\n",
        "    plt.axvline(median_area, color='green', linestyle='--', label=f'Median: {median_area:.2f} m²')\n",
        "    plt.title('Distribution of Solar Panel Areas (in square meters)')\n",
        "    plt.xlabel('Area (m²)')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.boxplot(y=all_areas)\n",
        "    plt.title('Boxplot of Solar Panel Areas')\n",
        "    plt.ylabel('Area (m²)')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "    def plot_random_samples(images_dir, labels_dir, num_samples=3, img_size=416):\n",
        "        image_files = glob.glob(os.path.join(images_dir, '*.tif')) + \\\n",
        "                      glob.glob(os.path.join(images_dir, '*.jpg')) + \\\n",
        "                      glob.glob(os.path.join(images_dir, '*.png'))\n",
        "\n",
        "        samples = np.random.choice(image_files, min(num_samples, len(image_files)), replace=False)\n",
        "\n",
        "        fig, axes = plt.subplots(1, len(samples), figsize=(15, 5))\n",
        "        if len(samples) == 1:\n",
        "            axes = [axes]\n",
        "\n",
        "        for i, img_path in enumerate(samples):\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            base_name = os.path.basename(img_path).split('.')[0]\n",
        "            label_path = os.path.join(labels_dir, f\"{base_name}.txt\")\n",
        "\n",
        "            labels = read_yolo_labels(label_path)\n",
        "\n",
        "            axes[i].imshow(img)\n",
        "            axes[i].set_title(f\"Image: {base_name}\\nPanels: {len(labels)}\")\n",
        "\n",
        "            for label in labels:\n",
        "                x_center = label['x_center'] * img_size\n",
        "                y_center = label['y_center'] * img_size\n",
        "                width = label['width'] * img_size\n",
        "                height = label['height'] * img_size\n",
        "\n",
        "                x1 = int(x_center - width/2)\n",
        "                y1 = int(y_center - height/2)\n",
        "                x2 = int(x_center + width/2)\n",
        "                y2 = int(y_center + height/2)\n",
        "\n",
        "                rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
        "                                    fill=False, edgecolor='red', linewidth=2)\n",
        "                axes[i].add_patch(rect)\n",
        "\n",
        "                area = (width * 0.31) * (height * 0.31)  # in square meters\n",
        "                axes[i].text(x1, y1-5, f\"{area:.1f}m²\", color='white',\n",
        "                            backgroundcolor='red', fontsize=8)\n",
        "\n",
        "            axes[i].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    print(\"\\n4. Plotting random samples with bounding boxes and area calculations:\")\n",
        "    plot_random_samples(train_dir, train_labels_dir)\n",
        "\n",
        "else:\n",
        "    print(\"\\n3. No area data available. Check if images and labels are properly loaded.\")"
      ],
      "metadata": {
        "id": "3HLpuXWytlmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "\n",
        "# Set paths\n",
        "data_dir = '/content/solar_panel_detection/data'\n",
        "train_dir = os.path.join(data_dir, 'images/train')\n",
        "train_labels_dir = os.path.join(data_dir, 'labels/train')\n",
        "val_dir = os.path.join(data_dir, 'images/val')\n",
        "val_labels_dir = os.path.join(data_dir, 'labels/val')\n",
        "test_dir = os.path.join(data_dir, 'images/test')\n",
        "test_labels_dir = os.path.join(data_dir, 'labels/test')\n",
        "\n",
        "# Function to read YOLO format labels\n",
        "def read_yolo_labels(label_path):\n",
        "    if not os.path.exists(label_path):\n",
        "        return []\n",
        "\n",
        "    with open(label_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    labels = []\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()\n",
        "        if len(parts) >= 5:  # class, x, y, width, height\n",
        "            label = {\n",
        "                'class': int(parts[0]),\n",
        "                'x_center': float(parts[1]),\n",
        "                'y_center': float(parts[2]),\n",
        "                'width': float(parts[3]),\n",
        "                'height': float(parts[4])\n",
        "            }\n",
        "            labels.append(label)\n",
        "\n",
        "    return labels\n",
        "\n",
        "# Function to parse tile and location info from filename\n",
        "def parse_filename(filename):\n",
        "    # Example: solarpanels_native_1__x0_0_y0_14027_dxdy_416.tif\n",
        "    parts = filename.split('__')\n",
        "    if len(parts) < 2:\n",
        "        return None\n",
        "\n",
        "    tile_info = parts[0].split('_')\n",
        "    if len(tile_info) < 3:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        tile_number = int(tile_info[-1])\n",
        "\n",
        "        # Parse x, y coordinates\n",
        "        coord_parts = parts[1].split('_')\n",
        "        x_min = int(coord_parts[1])\n",
        "        y_min = int(coord_parts[3])\n",
        "\n",
        "        return {\n",
        "            'tile': tile_number,\n",
        "            'x_min': x_min,\n",
        "            'y_min': y_min\n",
        "        }\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Function to compute label statistics\n",
        "def compute_dataset_stats(images_dir, labels_dir):\n",
        "    image_files = glob.glob(os.path.join(images_dir, '*.tif')) + \\\n",
        "                  glob.glob(os.path.join(images_dir, '*.jpg')) + \\\n",
        "                  glob.glob(os.path.join(images_dir, '*.png'))\n",
        "\n",
        "    total_instances = 0\n",
        "    labels_per_image = {}\n",
        "    areas = []\n",
        "\n",
        "    # GSD for native resolution (from README geotransform)\n",
        "    gsd = 0.31  # meters per pixel\n",
        "\n",
        "    # Track instances per tile for analysis\n",
        "    instances_per_tile = Counter()\n",
        "\n",
        "    for img_path in image_files:\n",
        "        # Get filename and parse info\n",
        "        filename = os.path.basename(img_path)\n",
        "        base_name = os.path.splitext(filename)[0]\n",
        "\n",
        "        # Parse tile info from filename if possible\n",
        "        tile_info = parse_filename(filename)\n",
        "\n",
        "        # Get corresponding label file\n",
        "        label_path = os.path.join(labels_dir, f\"{base_name}.txt\")\n",
        "\n",
        "        # Read labels\n",
        "        labels = read_yolo_labels(label_path)\n",
        "\n",
        "        # Count instances\n",
        "        num_labels = len(labels)\n",
        "        total_instances += num_labels\n",
        "\n",
        "        # Track instances per tile if info available\n",
        "        if tile_info:\n",
        "            instances_per_tile[tile_info['tile']] += num_labels\n",
        "\n",
        "        # Track labels per image\n",
        "        if num_labels in labels_per_image:\n",
        "            labels_per_image[num_labels] += 1\n",
        "        else:\n",
        "            labels_per_image[num_labels] = 1\n",
        "\n",
        "        # Calculate areas\n",
        "        if num_labels > 0:\n",
        "            img_size = 416  # Native resolution chip size from README\n",
        "\n",
        "            for label in labels:\n",
        "                # Convert normalized dimensions to pixel dimensions\n",
        "                width_pixels = label['width'] * img_size\n",
        "                height_pixels = label['height'] * img_size\n",
        "\n",
        "                # Convert to meters using the GSD\n",
        "                width_meters = width_pixels * gsd\n",
        "                height_meters = height_pixels * gsd\n",
        "\n",
        "                # Calculate area in square meters - using bounding box area\n",
        "                # Note: This is an approximation as panels might be at angles\n",
        "                area_meters = width_meters * height_meters\n",
        "\n",
        "                # Store the area\n",
        "                areas.append(area_meters)\n",
        "\n",
        "    return total_instances, labels_per_image, areas, instances_per_tile\n",
        "\n",
        "# Calculate statistics for each dataset split\n",
        "print(\"Analyzing training set...\")\n",
        "train_instances, train_labels_dist, train_areas, train_instances_per_tile = compute_dataset_stats(train_dir, train_labels_dir)\n",
        "print(\"Analyzing validation set...\")\n",
        "val_instances, val_labels_dist, val_areas, val_instances_per_tile = compute_dataset_stats(val_dir, val_labels_dir)\n",
        "print(\"Analyzing test set...\")\n",
        "test_instances, test_labels_dist, test_areas, test_instances_per_tile = compute_dataset_stats(test_dir, test_labels_dir)\n",
        "\n",
        "# Combine statistics\n",
        "total_instances = train_instances + val_instances + test_instances\n",
        "all_areas = train_areas + val_areas + test_areas\n",
        "\n",
        "# Combine label distributions\n",
        "all_labels_dist = {}\n",
        "for dist in [train_labels_dist, val_labels_dist, test_labels_dist]:\n",
        "    for num_labels, count in dist.items():\n",
        "        if num_labels in all_labels_dist:\n",
        "            all_labels_dist[num_labels] += count\n",
        "        else:\n",
        "            all_labels_dist[num_labels] = count\n",
        "\n",
        "# Sort the labels distribution\n",
        "sorted_labels_dist = dict(sorted(all_labels_dist.items()))\n",
        "\n",
        "# Combine instances per tile\n",
        "all_instances_per_tile = Counter()\n",
        "for counter in [train_instances_per_tile, val_instances_per_tile, test_instances_per_tile]:\n",
        "    all_instances_per_tile.update(counter)\n",
        "\n",
        "# 1. Print total instances\n",
        "print(f\"\\n1. Total solar panel instances in the dataset: {total_instances}\")\n",
        "\n",
        "# Print instances per tile if available\n",
        "if all_instances_per_tile:\n",
        "    print(\"\\nInstances per tile:\")\n",
        "    for tile, count in sorted(all_instances_per_tile.items()):\n",
        "        print(f\"   Tile {tile}: {count} instances\")\n",
        "\n",
        "# 2. Print label count distribution\n",
        "print(\"\\n2. Label count distribution (labels per image):\")\n",
        "for num_labels, count in sorted_labels_dist.items():\n",
        "    print(f\"   {count} images have {num_labels} labels\")\n",
        "\n",
        "# 3. Calculate area statistics\n",
        "if all_areas:\n",
        "    mean_area = np.mean(all_areas)\n",
        "    std_area = np.std(all_areas)\n",
        "    min_area = np.min(all_areas)\n",
        "    max_area = np.max(all_areas)\n",
        "    median_area = np.median(all_areas)\n",
        "\n",
        "    print(\"\\n3. Solar panel area statistics (in square meters):\")\n",
        "    print(f\"   Method: Calculated from bounding box dimensions using GSD of 31 cm per pixel\")\n",
        "    print(f\"   Note: The area calculation is an approximation as solar panels may be at angles within bounding boxes\")\n",
        "    print(f\"   Mean area: {mean_area:.2f} m²\")\n",
        "    print(f\"   Median area: {median_area:.2f} m²\")\n",
        "    print(f\"   Standard deviation: {std_area:.2f} m²\")\n",
        "    print(f\"   Min area: {min_area:.2f} m²\")\n",
        "    print(f\"   Max area: {max_area:.2f} m²\")\n",
        "\n",
        "    # 4. Plot histogram of areas\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Create histogram with KDE\n",
        "    sns.histplot(all_areas, bins=30, kde=True, color='skyblue')\n",
        "\n",
        "    # Add mean and median lines\n",
        "    plt.axvline(mean_area, color='red', linestyle='--', label=f'Mean: {mean_area:.2f} m²')\n",
        "    plt.axvline(median_area, color='green', linestyle='--', label=f'Median: {median_area:.2f} m²')\n",
        "\n",
        "    # Add annotations for key observations\n",
        "    if mean_area > median_area:\n",
        "        skew_direction = \"right (positive skew)\"\n",
        "        plt.annotate(\"Right-skewed: More smaller panels, fewer larger ones\",\n",
        "                     xy=(mean_area, 0), xytext=(mean_area+3, max(plt.gca().get_yticks())/3),\n",
        "                     arrowprops=dict(facecolor='black', shrink=0.05, width=1.5, headwidth=8))\n",
        "    else:\n",
        "        skew_direction = \"left (negative skew)\"\n",
        "        plt.annotate(\"Left-skewed: More larger panels, fewer smaller ones\",\n",
        "                     xy=(mean_area, 0), xytext=(mean_area-3, max(plt.gca().get_yticks())/3),\n",
        "                     arrowprops=dict(facecolor='black', shrink=0.05, width=1.5, headwidth=8))\n",
        "\n",
        "    # Calculate skewness for more precise assessment\n",
        "    from scipy.stats import skew\n",
        "    skewness = skew(all_areas)\n",
        "\n",
        "    # Analyze modality (unimodal, bimodal, etc.)\n",
        "    from scipy.stats import gaussian_kde\n",
        "    kde = gaussian_kde(all_areas)\n",
        "    x = np.linspace(min(all_areas), max(all_areas), 1000)\n",
        "    y = kde(x)\n",
        "\n",
        "    # Find peaks (local maxima)\n",
        "    from scipy.signal import find_peaks\n",
        "    peaks, _ = find_peaks(y)\n",
        "    num_peaks = len(peaks)\n",
        "\n",
        "    modality = \"Unimodal\" if num_peaks <= 1 else \"Bimodal\" if num_peaks == 2 else \"Multimodal\"\n",
        "\n",
        "    plt.title(f'Distribution of Solar Panel Areas (in square meters)\\n{modality}, Skewed to {skew_direction}, Skewness: {skewness:.2f}')\n",
        "    plt.xlabel('Area (m²)')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "    # Add commentary about observations\n",
        "    print(\"\\nObservations from histogram:\")\n",
        "    print(f\"1. The distribution is {modality.lower()} with {num_peaks} distinct peak(s).\")\n",
        "    print(f\"2. The distribution is skewed to the {skew_direction} with a skewness value of {skewness:.2f}.\")\n",
        "    print(f\"3. Mean ({mean_area:.2f} m²) is {'greater' if mean_area > median_area else 'less'} than median ({median_area:.2f} m²).\")\n",
        "\n",
        "    if mean_area > median_area:\n",
        "        print(\"4. This suggests there are more smaller solar panels in the dataset, with fewer but larger panels pulling the mean upward.\")\n",
        "    else:\n",
        "        print(\"4. This suggests there are more larger solar panels in the dataset, with fewer but smaller panels pulling the mean downward.\")\n",
        "\n",
        "    # Identify any clusters or groups in the distribution\n",
        "    if num_peaks > 1:\n",
        "        peak_areas = x[peaks]\n",
        "        print(f\"5. There appear to be distinct size groups centered around: {', '.join([f'{a:.2f} m²' for a in peak_areas])}\")\n",
        "        print(\"   This could indicate different types or installations of solar panels in the dataset.\")\n",
        "\n",
        "    # 5. Additional visualization: boxplot to show outliers\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.boxplot(y=all_areas)\n",
        "    plt.title('Boxplot of Solar Panel Areas')\n",
        "    plt.ylabel('Area (m²)')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "    # Check for outliers using IQR method\n",
        "    Q1 = np.percentile(all_areas, 25)\n",
        "    Q3 = np.percentile(all_areas, 75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    outlier_lower = Q1 - 1.5 * IQR\n",
        "    outlier_upper = Q3 + 1.5 * IQR\n",
        "\n",
        "    outliers = [area for area in all_areas if area < outlier_lower or area > outlier_upper]\n",
        "    outlier_percentage = len(outliers) / len(all_areas) * 100\n",
        "\n",
        "    print(f\"\\nOutlier Analysis:\")\n",
        "    print(f\"1. Using the IQR method, {len(outliers)} outliers were detected ({outlier_percentage:.2f}% of all instances).\")\n",
        "    print(f\"2. Outlier boundaries: < {outlier_lower:.2f} m² or > {outlier_upper:.2f} m²\")\n",
        "\n",
        "    if outliers:\n",
        "        print(f\"3. Min outlier: {min(outliers):.2f} m², Max outlier: {max(outliers):.2f} m²\")\n",
        "\n",
        "    # 6. Visualize some examples to verify calculations\n",
        "    def plot_random_samples(images_dir, labels_dir, num_samples=3, img_size=416):\n",
        "        image_files = glob.glob(os.path.join(images_dir, '*.tif')) + \\\n",
        "                      glob.glob(os.path.join(images_dir, '*.jpg')) + \\\n",
        "                      glob.glob(os.path.join(images_dir, '*.png'))\n",
        "\n",
        "        if not image_files:\n",
        "            print(\"No image files found for visualization.\")\n",
        "            return\n",
        "\n",
        "        # Select random samples\n",
        "        samples = np.random.choice(image_files, min(num_samples, len(image_files)), replace=False)\n",
        "\n",
        "        fig, axes = plt.subplots(1, len(samples), figsize=(15, 5))\n",
        "        if len(samples) == 1:\n",
        "            axes = [axes]\n",
        "\n",
        "        for i, img_path in enumerate(samples):\n",
        "            # Read image\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                print(f\"Could not read image: {img_path}\")\n",
        "                continue\n",
        "\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Get corresponding label file\n",
        "            base_name = os.path.basename(img_path).split('.')[0]\n",
        "            label_path = os.path.join(labels_dir, f\"{base_name}.txt\")\n",
        "\n",
        "            # Read labels\n",
        "            labels = read_yolo_labels(label_path)\n",
        "\n",
        "            # Display image\n",
        "            axes[i].imshow(img)\n",
        "            axes[i].set_title(f\"Image: {os.path.basename(img_path)}\\nPanels: {len(labels)}\")\n",
        "\n",
        "            # Draw bounding boxes and calculate areas\n",
        "            for label in labels:\n",
        "                # Convert normalized coordinates to pixel coordinates\n",
        "                x_center = label['x_center'] * img_size\n",
        "                y_center = label['y_center'] * img_size\n",
        "                width = label['width'] * img_size\n",
        "                height = label['height'] * img_size\n",
        "\n",
        "                x1 = int(x_center - width/2)\n",
        "                y1 = int(y_center - height/2)\n",
        "                x2 = int(x_center + width/2)\n",
        "                y2 = int(y_center + height/2)\n",
        "\n",
        "                # Draw rectangle\n",
        "                rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
        "                                    fill=False, edgecolor='red', linewidth=2)\n",
        "                axes[i].add_patch(rect)\n",
        "\n",
        "                # Calculate area\n",
        "                area = (width * 0.31) * (height * 0.31)  # in square meters\n",
        "                axes[i].text(x1, y1-5, f\"{area:.1f}m²\", color='white',\n",
        "                            backgroundcolor='red', fontsize=8)\n",
        "\n",
        "            axes[i].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    print(\"\\nPlotting random samples with bounding boxes and area calculations:\")\n",
        "    plot_random_samples(train_dir, train_labels_dir)\n",
        "else:\n",
        "    print(\"\\n3. No area data available. Check if images and labels are properly loaded.\")"
      ],
      "metadata": {
        "id": "8nz_TRArviF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from shapely.geometry import box\n",
        "import supervision as sv\n",
        "import random\n",
        "from typing import List, Tuple, Union, Dict\n",
        "\n",
        "# Function to compute IoU using Shapely\n",
        "def compute_iou_shapely(box1: List[float], box2: List[float]) -> float:\n",
        "    \"\"\"\n",
        "    Compute IoU between two axis-aligned bounding boxes using Shapely.\n",
        "\n",
        "    Args:\n",
        "        box1: [x_center, y_center, width, height] in normalized coordinates (0-1)\n",
        "        box2: [x_center, y_center, width, height] in normalized coordinates (0-1)\n",
        "\n",
        "    Returns:\n",
        "        iou: Intersection over Union score\n",
        "    \"\"\"\n",
        "    # Convert from [x_center, y_center, width, height] to [xmin, ymin, xmax, ymax]\n",
        "    def yolo_to_xyxy(box):\n",
        "        x_center, y_center, width, height = box\n",
        "        xmin = x_center - width / 2\n",
        "        ymin = y_center - height / 2\n",
        "        xmax = x_center + width / 2\n",
        "        ymax = y_center + height / 2\n",
        "        return [xmin, ymin, xmax, ymax]\n",
        "\n",
        "    # Convert to xyxy format\n",
        "    box1_xyxy = yolo_to_xyxy(box1)\n",
        "    box2_xyxy = yolo_to_xyxy(box2)\n",
        "\n",
        "    # Create Shapely boxes\n",
        "    shapely_box1 = box(box1_xyxy[0], box1_xyxy[1], box1_xyxy[2], box1_xyxy[3])\n",
        "    shapely_box2 = box(box2_xyxy[0], box2_xyxy[1], box2_xyxy[2], box2_xyxy[3])\n",
        "\n",
        "    # Compute intersection and union\n",
        "    if not shapely_box1.intersects(shapely_box2):\n",
        "        return 0.0\n",
        "\n",
        "    intersection = shapely_box1.intersection(shapely_box2).area\n",
        "    union = shapely_box1.area + shapely_box2.area - intersection\n",
        "\n",
        "    # Compute IoU\n",
        "    iou = intersection / union if union > 0 else 0.0\n",
        "    return iou\n",
        "\n",
        "# Function to compute IoU using supervision library for comparison\n",
        "def compute_iou_supervision(box1: List[float], box2: List[float]) -> float:\n",
        "    \"\"\"\n",
        "    Compute IoU between two axis-aligned bounding boxes using supervision library.\n",
        "\n",
        "    Args:\n",
        "        box1: [x_center, y_center, width, height] in normalized coordinates (0-1)\n",
        "        box2: [x_center, y_center, width, height] in normalized coordinates (0-1)\n",
        "\n",
        "    Returns:\n",
        "        iou: Intersection over Union score\n",
        "    \"\"\"\n",
        "    # Convert from [x_center, y_center, width, height] to [xmin, ymin, xmax, ymax]\n",
        "    def yolo_to_xyxy(box):\n",
        "        x_center, y_center, width, height = box\n",
        "        xmin = x_center - width / 2\n",
        "        ymin = y_center - height / 2\n",
        "        xmax = x_center + width / 2\n",
        "        ymax = y_center + height / 2\n",
        "        return [xmin, ymin, xmax, ymax]\n",
        "\n",
        "    # Convert to xyxy format\n",
        "    box1_xyxy = yolo_to_xyxy(box1)\n",
        "    box2_xyxy = yolo_to_xyxy(box2)\n",
        "\n",
        "    # Create supervision Detections objects\n",
        "    detection1 = sv.Detections(\n",
        "        xyxy=np.array([box1_xyxy]),\n",
        "        class_id=np.array([0]),\n",
        "        confidence=np.array([1.0])\n",
        "    )\n",
        "\n",
        "    detection2 = sv.Detections(\n",
        "        xyxy=np.array([box2_xyxy]),\n",
        "        class_id=np.array([0]),\n",
        "        confidence=np.array([1.0])\n",
        "    )\n",
        "\n",
        "    # Compute IoU matrix\n",
        "    iou_matrix = sv.box_iou_batch(detection1.xyxy, detection2.xyxy)\n",
        "    return iou_matrix[0, 0]\n",
        "\n",
        "# Test the IoU functions with a simple example\n",
        "def test_iou_functions():\n",
        "    box1 = [0.5, 0.5, 0.4, 0.4]  # [x_center, y_center, width, height]\n",
        "    box2 = [0.6, 0.6, 0.4, 0.4]\n",
        "\n",
        "    iou_shapely = compute_iou_shapely(box1, box2)\n",
        "    iou_supervision = compute_iou_supervision(box1, box2)\n",
        "\n",
        "    print(f\"IoU using Shapely: {iou_shapely:.4f}\")\n",
        "    print(f\"IoU using supervision: {iou_supervision:.4f}\")\n",
        "    print(f\"Difference: {abs(iou_shapely - iou_supervision):.6f}\")\n",
        "\n",
        "# Function to compute AP using Pascal VOC 11-point interpolation\n",
        "def compute_ap_pascal_voc(precisions: np.ndarray, recalls: np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    Compute Average Precision using Pascal VOC 11-point interpolation.\n",
        "\n",
        "    Args:\n",
        "        precisions: Array of precision values at different recall thresholds\n",
        "        recalls: Array of recall values\n",
        "\n",
        "    Returns:\n",
        "        ap: Average Precision score (0-1)\n",
        "    \"\"\"\n",
        "    # Ensure precisions and recalls are numpy arrays\n",
        "    precisions = np.array(precisions)\n",
        "    recalls = np.array(recalls)\n",
        "\n",
        "    # Use 11 recall points from 0 to 1\n",
        "    ap = 0.0\n",
        "    for recall_threshold in np.linspace(0, 1, 11):\n",
        "        # Get precision values where recall >= threshold\n",
        "        precision_values = precisions[recalls >= recall_threshold]\n",
        "\n",
        "        # Use max precision if there are any values, else 0\n",
        "        max_precision = np.max(precision_values) if len(precision_values) > 0 else 0\n",
        "        ap += max_precision\n",
        "\n",
        "    # Average over the 11 points\n",
        "    ap /= 11\n",
        "    return ap\n",
        "\n",
        "# Function to compute AP using COCO 101-point interpolation\n",
        "def compute_ap_coco(precisions: np.ndarray, recalls: np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    Compute Average Precision using COCO 101-point interpolation.\n",
        "\n",
        "    Args:\n",
        "        precisions: Array of precision values at different recall thresholds\n",
        "        recalls: Array of recall values\n",
        "\n",
        "    Returns:\n",
        "        ap: Average Precision score (0-1)\n",
        "    \"\"\"\n",
        "    # Ensure precisions and recalls are numpy arrays\n",
        "    precisions = np.array(precisions)\n",
        "    recalls = np.array(recalls)\n",
        "\n",
        "    # Use 101 recall points from 0 to 1\n",
        "    ap = 0.0\n",
        "    for recall_threshold in np.linspace(0, 1, 101):\n",
        "        # Get precision values where recall >= threshold\n",
        "        precision_values = precisions[recalls >= recall_threshold]\n",
        "\n",
        "        # Use max precision if there are any values, else 0\n",
        "        max_precision = np.max(precision_values) if len(precision_values) > 0 else 0\n",
        "        ap += max_precision\n",
        "\n",
        "    # Average over the 101 points\n",
        "    ap /= 101\n",
        "    return ap\n",
        "\n",
        "# Function to compute AP using Area under Precision-Recall Curve\n",
        "def compute_ap_auc(precisions: np.ndarray, recalls: np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    Compute Average Precision using Area under Precision-Recall Curve.\n",
        "\n",
        "    Args:\n",
        "        precisions: Array of precision values at different recall thresholds\n",
        "        recalls: Array of recall values\n",
        "\n",
        "    Returns:\n",
        "        ap: Average Precision score (0-1)\n",
        "    \"\"\"\n",
        "    # Ensure precisions and recalls are numpy arrays\n",
        "    precisions = np.array(precisions)\n",
        "    recalls = np.array(recalls)\n",
        "\n",
        "    # Sort by recalls\n",
        "    sorted_indices = np.argsort(recalls)\n",
        "    recalls = recalls[sorted_indices]\n",
        "    precisions = precisions[sorted_indices]\n",
        "\n",
        "    # Append start and end points\n",
        "    recalls = np.concatenate([[0], recalls, [1]])\n",
        "    precisions = np.concatenate([[0], precisions, [0]])\n",
        "\n",
        "    # Area under curve using trapezoidal rule\n",
        "    ap = 0.0\n",
        "    for i in range(len(recalls) - 1):\n",
        "        ap += (recalls[i + 1] - recalls[i]) * (precisions[i] + precisions[i + 1]) / 2\n",
        "\n",
        "    return ap\n",
        "\n",
        "# Function to generate random boxes\n",
        "def generate_random_boxes(n: int, image_size: int, box_size: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Generate n random boxes of given size in an image.\n",
        "\n",
        "    Args:\n",
        "        n: Number of boxes\n",
        "        image_size: Size of the image (square)\n",
        "        box_size: Size of the boxes (square)\n",
        "\n",
        "    Returns:\n",
        "        boxes: Array of shape (n, 4) with [x_center, y_center, width, height] in normalized coords\n",
        "    \"\"\"\n",
        "    boxes = []\n",
        "    for _ in range(n):\n",
        "        # Generate center coordinates ensuring box stays within image\n",
        "        half_box_size = box_size / 2\n",
        "        min_coord = half_box_size\n",
        "        max_coord = image_size - half_box_size\n",
        "\n",
        "        x_center = random.uniform(min_coord, max_coord) / image_size\n",
        "        y_center = random.uniform(min_coord, max_coord) / image_size\n",
        "\n",
        "        width = box_size / image_size\n",
        "        height = box_size / image_size\n",
        "\n",
        "        boxes.append([x_center, y_center, width, height])\n",
        "\n",
        "    return np.array(boxes)\n",
        "\n",
        "# Function to compute precision and recall at a given IoU threshold\n",
        "def compute_precision_recall(gt_boxes: List[np.ndarray],\n",
        "                            pred_boxes: List[np.ndarray],\n",
        "                            pred_scores: List[np.ndarray],\n",
        "                            iou_threshold: float = 0.5) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Compute precision and recall values at different confidence thresholds.\n",
        "\n",
        "    Args:\n",
        "        gt_boxes: List of arrays of ground truth boxes, one array per image\n",
        "        pred_boxes: List of arrays of predicted boxes, one array per image\n",
        "        pred_scores: List of arrays of confidence scores, one array per image\n",
        "        iou_threshold: IoU threshold to determine true positives\n",
        "\n",
        "    Returns:\n",
        "        precisions: Array of precision values\n",
        "        recalls: Array of recall values\n",
        "    \"\"\"\n",
        "    # Flatten all predictions across images\n",
        "    all_preds = []\n",
        "    for img_idx, (boxes, scores) in enumerate(zip(pred_boxes, pred_scores)):\n",
        "        for box_idx, (box, score) in enumerate(zip(boxes, scores)):\n",
        "            all_preds.append({\n",
        "                'img_idx': img_idx,\n",
        "                'box': box,\n",
        "                'score': score\n",
        "            })\n",
        "\n",
        "    # Sort predictions by confidence score (descending)\n",
        "    all_preds.sort(key=lambda x: x['score'], reverse=True)\n",
        "\n",
        "    # Count total ground truth boxes\n",
        "    total_gt = sum(len(boxes) for boxes in gt_boxes)\n",
        "\n",
        "    # Initialize arrays for true positives and false positives\n",
        "    tp = np.zeros(len(all_preds))\n",
        "    fp = np.zeros(len(all_preds))\n",
        "\n",
        "    # Keep track of which ground truth boxes have been detected\n",
        "    detected_gt = [set() for _ in range(len(gt_boxes))]\n",
        "\n",
        "    # Process predictions in order of confidence\n",
        "    for pred_idx, pred in enumerate(all_preds):\n",
        "        img_idx = pred['img_idx']\n",
        "        pred_box = pred['box']\n",
        "\n",
        "        # Get ground truth boxes for this image\n",
        "        if img_idx >= len(gt_boxes) or len(gt_boxes[img_idx]) == 0:\n",
        "            # No ground truth boxes in this image\n",
        "            fp[pred_idx] = 1\n",
        "            continue\n",
        "\n",
        "        # Find best matching ground truth box\n",
        "        best_iou = -1\n",
        "        best_gt_idx = -1\n",
        "\n",
        "        for gt_idx, gt_box in enumerate(gt_boxes[img_idx]):\n",
        "            if gt_idx in detected_gt[img_idx]:\n",
        "                # This ground truth box has already been detected\n",
        "                continue\n",
        "\n",
        "            iou = compute_iou_shapely(pred_box, gt_box)\n",
        "\n",
        "            if iou > best_iou:\n",
        "                best_iou = iou\n",
        "                best_gt_idx = gt_idx\n",
        "\n",
        "        # Check if the detection is correct (IoU > threshold)\n",
        "        if best_iou >= iou_threshold:\n",
        "            tp[pred_idx] = 1\n",
        "            detected_gt[img_idx].add(best_gt_idx)\n",
        "        else:\n",
        "            fp[pred_idx] = 1\n",
        "\n",
        "    # Compute cumulative sums\n",
        "    cum_tp = np.cumsum(tp)\n",
        "    cum_fp = np.cumsum(fp)\n",
        "\n",
        "    # Compute precision and recall\n",
        "    precisions = np.divide(cum_tp, cum_tp + cum_fp, where=(cum_tp + cum_fp) > 0)\n",
        "    recalls = cum_tp / total_gt if total_gt > 0 else np.zeros_like(cum_tp)\n",
        "\n",
        "    return precisions, recalls\n",
        "\n",
        "# Function to evaluate AP50 using multiple methods\n",
        "def evaluate_ap50(gt_boxes: List[np.ndarray],\n",
        "                 pred_boxes: List[np.ndarray],\n",
        "                 pred_scores: List[np.ndarray]) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Evaluate AP50 using different AP calculation methods.\n",
        "\n",
        "    Args:\n",
        "        gt_boxes: List of arrays of ground truth boxes, one array per image\n",
        "        pred_boxes: List of arrays of predicted boxes, one array per image\n",
        "        pred_scores: List of arrays of confidence scores, one array per image\n",
        "\n",
        "    Returns:\n",
        "        results: Dictionary with AP50 values for different methods\n",
        "    \"\"\"\n",
        "    # Compute precision and recall at IoU threshold 0.5\n",
        "    precisions, recalls = compute_precision_recall(gt_boxes, pred_boxes, pred_scores, iou_threshold=0.5)\n",
        "\n",
        "    # Compute AP using different methods\n",
        "    ap_pascal_voc = compute_ap_pascal_voc(precisions, recalls)\n",
        "    ap_coco = compute_ap_coco(precisions, recalls)\n",
        "    ap_auc = compute_ap_auc(precisions, recalls)\n",
        "\n",
        "    results = {\n",
        "        'AP50 (Pascal VOC 11-point)': ap_pascal_voc,\n",
        "        'AP50 (COCO 101-point)': ap_coco,\n",
        "        'AP50 (AUC)': ap_auc\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "# Function to generate random test data\n",
        "def generate_test_data(num_images: int = 10,\n",
        "                      image_size: int = 100,\n",
        "                      box_size: int = 20,\n",
        "                      boxes_per_image: int = 10) -> Tuple[List[np.ndarray], List[np.ndarray], List[np.ndarray]]:\n",
        "    \"\"\"\n",
        "    Generate random test data with ground truth and predicted boxes.\n",
        "\n",
        "    Args:\n",
        "        num_images: Number of images to generate\n",
        "        image_size: Size of each image (square)\n",
        "        box_size: Size of boxes (square)\n",
        "        boxes_per_image: Number of boxes per image\n",
        "\n",
        "    Returns:\n",
        "        gt_boxes: List of arrays of ground truth boxes\n",
        "        pred_boxes: List of arrays of predicted boxes\n",
        "        pred_scores: List of arrays of confidence scores\n",
        "    \"\"\"\n",
        "    gt_boxes = []\n",
        "    pred_boxes = []\n",
        "    pred_scores = []\n",
        "\n",
        "    for _ in range(num_images):\n",
        "        # Generate ground truth boxes\n",
        "        gt = generate_random_boxes(boxes_per_image, image_size, box_size)\n",
        "        gt_boxes.append(gt)\n",
        "\n",
        "        # Generate predicted boxes with some noise\n",
        "        pred = []\n",
        "        scores = []\n",
        "\n",
        "        for gt_box in gt:\n",
        "            # Add noise to box position (50% of the time)\n",
        "            if random.random() < 0.5:\n",
        "                x_noise = random.uniform(-0.1, 0.1)\n",
        "                y_noise = random.uniform(-0.1, 0.1)\n",
        "                w_noise = random.uniform(-0.05, 0.05)\n",
        "                h_noise = random.uniform(-0.05, 0.05)\n",
        "\n",
        "                pred_box = [\n",
        "                    max(0, min(1, gt_box[0] + x_noise)),\n",
        "                    max(0, min(1, gt_box[1] + y_noise)),\n",
        "                    max(0.01, min(0.99, gt_box[2] + w_noise)),\n",
        "                    max(0.01, min(0.99, gt_box[3] + h_noise))\n",
        "                ]\n",
        "            else:\n",
        "                # Exact match (50% of the time)\n",
        "                pred_box = gt_box.copy()\n",
        "\n",
        "            pred.append(pred_box)\n",
        "\n",
        "            # Generate random confidence score\n",
        "            score = random.uniform(0.5, 1.0)\n",
        "            scores.append(score)\n",
        "\n",
        "        pred_boxes.append(np.array(pred))\n",
        "        pred_scores.append(np.array(scores))\n",
        "\n",
        "    return gt_boxes, pred_boxes, pred_scores\n",
        "\n",
        "# Function to visualize a few test images with ground truth and predicted boxes\n",
        "def visualize_test_data(gt_boxes: List[np.ndarray],\n",
        "                        pred_boxes: List[np.ndarray],\n",
        "                        image_size: int = 100,\n",
        "                        num_images: int = 3):\n",
        "    \"\"\"\n",
        "    Visualize a few test images with ground truth and predicted boxes.\n",
        "\n",
        "    Args:\n",
        "        gt_boxes: List of arrays of ground truth boxes\n",
        "        pred_boxes: List of arrays of predicted boxes\n",
        "        image_size: Size of each image (square)\n",
        "        num_images: Number of images to visualize\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n",
        "\n",
        "    for i in range(min(num_images, len(gt_boxes))):\n",
        "        # Create blank image\n",
        "        image = np.ones((image_size, image_size, 3))\n",
        "\n",
        "        # Convert normalized coordinates to pixel coordinates\n",
        "        def normalize_to_pixel(box):\n",
        "            x_center, y_center, width, height = box\n",
        "            x_min = int((x_center - width / 2) * image_size)\n",
        "            y_min = int((y_center - height / 2) * image_size)\n",
        "            x_max = int((x_center + width / 2) * image_size)\n",
        "            y_max = int((y_center + height / 2) * image_size)\n",
        "            return [x_min, y_min, x_max, y_max]\n",
        "\n",
        "        # Draw ground truth boxes in green\n",
        "        for box in gt_boxes[i]:\n",
        "            x_min, y_min, x_max, y_max = normalize_to_pixel(box)\n",
        "            cv_box = np.array([[x_min, y_min], [x_max, y_min], [x_max, y_max], [x_min, y_max]])\n",
        "            cv_box = cv_box.reshape((-1, 1, 2))\n",
        "            image = cv2.polylines(image.copy(), [cv_box], True, (0, 1, 0), 2)\n",
        "\n",
        "        # Draw predicted boxes in red\n",
        "        for box in pred_boxes[i]:\n",
        "            x_min, y_min, x_max, y_max = normalize_to_pixel(box)\n",
        "            cv_box = np.array([[x_min, y_min], [x_max, y_min], [x_max, y_max], [x_min, y_max]])\n",
        "            cv_box = cv_box.reshape((-1, 1, 2))\n",
        "            image = cv2.polylines(image.copy(), [cv_box], True, (1, 0, 0), 1)\n",
        "\n",
        "        # Show image\n",
        "        if num_images > 1:\n",
        "            axes[i].imshow(image)\n",
        "            axes[i].set_title(f\"Image {i+1}\")\n",
        "            axes[i].axis('off')\n",
        "        else:\n",
        "            axes.imshow(image)\n",
        "            axes.set_title(f\"Image {i+1}\")\n",
        "            axes.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Main function to run all evaluations\n",
        "def main():\n",
        "    # Test IoU functions\n",
        "    print(\"Testing IoU functions...\")\n",
        "    test_iou_functions()\n",
        "    print()\n",
        "\n",
        "    # Generate random test data\n",
        "    print(\"Generating random test data...\")\n",
        "    gt_boxes, pred_boxes, pred_scores = generate_test_data()\n",
        "    print(f\"Generated {len(gt_boxes)} images with {len(gt_boxes[0])} boxes each\")\n",
        "    print()\n",
        "\n",
        "    # Try to import cv2 for visualization\n",
        "    try:\n",
        "        import cv2\n",
        "        # Visualize some test images\n",
        "        print(\"Visualizing test data...\")\n",
        "        visualize_test_data(gt_boxes, pred_boxes)\n",
        "    except ImportError:\n",
        "        print(\"OpenCV (cv2) not available, skipping visualization\")\n",
        "\n",
        "    # Evaluate AP50 using different methods\n",
        "    print(\"Evaluating AP50 using different methods...\")\n",
        "    results = evaluate_ap50(gt_boxes, pred_boxes, pred_scores)\n",
        "\n",
        "    for method, ap50 in results.items():\n",
        "        print(f\"{method}: {ap50:.4f}\")\n",
        "    print()\n",
        "\n",
        "\n",
        "    precisions, recalls = compute_precision_recall(gt_boxes, pred_boxes, pred_scores)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(recalls, precisions, 'b-', linewidth=2)\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.grid(True)\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1.05])\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "TNYRUOJiv_QI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For model training with Ultralytics YOLO\n",
        "from ultralytics import YOLO\n",
        "import supervision as sv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# 1. Train the model using Ultralytics YOLO with the correct path to YAML\n",
        "model = YOLO('yolov8n.pt')  # Start with a pre-trained model\n",
        "results = model.train(\n",
        "    data='/content/solar_panel_detection/data/solar_panel.yaml',  # Correct path to existing YAML\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    patience=10,\n",
        "    batch=16,\n",
        "    save=True\n",
        ")\n",
        "\n",
        "# Check if validation loss has converged\n",
        "val_loss = results.results_dict['val/loss']\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(val_loss)\n",
        "plt.title('Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()\n",
        "\n",
        "# 2. Predict and visualize on test samples\n",
        "test_images_dir = '/content/solar_panel_detection/data/images/test'\n",
        "test_images = list(Path(test_images_dir).glob('*.jpg')) + list(Path(test_images_dir).glob('*.png'))\n",
        "random_samples = random.sample(test_images, min(4, len(test_images)))  # Select up to 4 random samples\n",
        "\n",
        "# Function to get ground truth from label files\n",
        "def get_ground_truth(img_path):\n",
        "    # Convert image path to label path\n",
        "    # Example: /content/solar_panel_detection/data/images/test/img.jpg\n",
        "    # to /content/solar_panel_detection/data/labels/test/img.txt\n",
        "    img_filename = os.path.basename(img_path)\n",
        "    img_name = os.path.splitext(img_filename)[0]\n",
        "    label_path = os.path.join('/content/solar_panel_detection/data/labels/test', f\"{img_name}.txt\")\n",
        "\n",
        "    boxes = []\n",
        "    if os.path.exists(label_path):\n",
        "        with open(label_path, 'r') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) >= 5:  # class, x, y, w, h\n",
        "                    # YOLO format: class_id, center_x, center_y, width, height (normalized)\n",
        "                    x, y, w, h = map(float, parts[1:5])\n",
        "                    boxes.append([x, y, w, h])\n",
        "    return boxes\n",
        "\n",
        "# Function to convert YOLO predictions to supervision format if needed\n",
        "def convert_to_supervision_format(yolo_boxes):\n",
        "    # This function would convert YOLO output to supervision format\n",
        "    # Implementation depends on your specific needs\n",
        "    # For simplicity, let's assume we're just passing through the data\n",
        "    return yolo_boxes\n",
        "\n",
        "for img_path in random_samples:\n",
        "    # Load image\n",
        "    img = cv2.imread(str(img_path))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    # Get ground truth\n",
        "    gt_boxes = get_ground_truth(img_path)\n",
        "\n",
        "    # Get predictions\n",
        "    results = model.predict(str(img_path), conf=0.25)\n",
        "    pred_boxes = results[0].boxes\n",
        "\n",
        "    # Visualize\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
        "    ax.imshow(img)\n",
        "\n",
        "    # Draw ground truth boxes (green)\n",
        "    for box in gt_boxes:\n",
        "        x, y, w_box, h_box = box\n",
        "        # Convert normalized coordinates to pixel coordinates\n",
        "        x1 = int((x - w_box/2) * w)\n",
        "        y1 = int((y - h_box/2) * h)\n",
        "        box_w = int(w_box * w)\n",
        "        box_h = int(h_box * h)\n",
        "\n",
        "        rect = plt.Rectangle((x1, y1), box_w, box_h, linewidth=2, edgecolor='green', facecolor='none')\n",
        "        ax.add_patch(rect)\n",
        "        ax.text(x1, y1, 'GT', color='green')\n",
        "\n",
        "    # Draw predicted boxes (red)\n",
        "    if hasattr(pred_boxes, 'xyxy') and len(pred_boxes.xyxy) > 0:\n",
        "        for i in range(len(pred_boxes.xyxy)):\n",
        "            x1, y1, x2, y2 = pred_boxes.xyxy[i].tolist()\n",
        "            conf = pred_boxes.conf[i].item()\n",
        "            rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, edgecolor='red', facecolor='none')\n",
        "            ax.add_patch(rect)\n",
        "            ax.text(x1, y1, f'Pred: {conf:.2f}', color='red')\n",
        "\n",
        "    plt.title(f'Solar Panel Detection: {os.path.basename(img_path)}')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# 3. Calculate mAP50 using supervision and compare with your implementation\n",
        "# Assuming you have functions to calculate mAP50\n",
        "def calculate_your_map50(model, test_images):\n",
        "    # This would be your custom implementation of mAP50\n",
        "    # For this example, I'll create a placeholder\n",
        "    # You should replace this with your actual implementation from your earlier code\n",
        "    return 0.75  # Placeholder\n",
        "\n",
        "def calculate_map50():\n",
        "    # Using supervision library\n",
        "    det_evaluator = sv.DetectionMetrics(\n",
        "        classes=[0],  # Assuming solar panel is class 0\n",
        "        iou_threshold=0.5\n",
        "    )\n",
        "\n",
        "    # Process your test set and update metrics\n",
        "    for img_path in test_images:\n",
        "        # Get ground truth and predictions for this image\n",
        "        gt_boxes = get_ground_truth(img_path)\n",
        "\n",
        "        # Convert ground truth to supervision format\n",
        "        sv_gts = []\n",
        "        if gt_boxes:\n",
        "            img = cv2.imread(str(img_path))\n",
        "            h, w = img.shape[:2]\n",
        "            for box in gt_boxes:\n",
        "                x, y, w_box, h_box = box\n",
        "                # Convert to xyxy format\n",
        "                x1 = (x - w_box/2) * w\n",
        "                y1 = (y - h_box/2) * h\n",
        "                x2 = (x + w_box/2) * w\n",
        "                y2 = (y + h_box/2) * h\n",
        "                sv_gts.append(sv.DetectionPrediction(xyxy=np.array([x1, y1, x2, y2]), class_id=0, confidence=1.0))\n",
        "\n",
        "        # Get predictions\n",
        "        pred_results = model.predict(str(img_path))\n",
        "\n",
        "        # Convert predictions to supervision format\n",
        "        sv_preds = []\n",
        "        if len(pred_results[0].boxes) > 0:\n",
        "            for i in range(len(pred_results[0].boxes.xyxy)):\n",
        "                x1, y1, x2, y2 = pred_results[0].boxes.xyxy[i].tolist()\n",
        "                conf = pred_results[0].boxes.conf[i].item()\n",
        "                sv_preds.append(sv.DetectionPrediction(xyxy=np.array([x1, y1, x2, y2]), class_id=0, confidence=conf))\n",
        "\n",
        "        # Update metrics\n",
        "        det_evaluator.update(preds=sv_preds, gts=sv_gts)\n",
        "\n",
        "    # Calculate mAP50 using supervision\n",
        "    supervision_map50 = det_evaluator.map()\n",
        "\n",
        "    # Calculate mAP50 using your implementation\n",
        "    your_map50 = calculate_your_map50(model, test_images)\n",
        "\n",
        "    print(f\"mAP50 (supervision): {supervision_map50:.4f}\")\n",
        "    print(f\"mAP50 (your implementation): {your_map50:.4f}\")\n",
        "    print(f\"Difference: {abs(supervision_map50 - your_map50):.4f}\")\n",
        "\n",
        "    return supervision_map50, your_map50\n",
        "\n",
        "# 4. Create metrics table for different IoU and confidence thresholds\n",
        "def create_metrics_table():\n",
        "    iou_thresholds = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
        "    conf_thresholds = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
        "\n",
        "    # Initialize result matrices\n",
        "    precision_matrix = np.zeros((len(iou_thresholds), len(conf_thresholds)))\n",
        "    recall_matrix = np.zeros((len(iou_thresholds), len(conf_thresholds)))\n",
        "    f1_matrix = np.zeros((len(iou_thresholds), len(conf_thresholds)))\n",
        "\n",
        "    # Calculate metrics for each combination\n",
        "    for i, iou_thresh in enumerate(iou_thresholds):\n",
        "        for j, conf_thresh in enumerate(conf_thresholds):\n",
        "            # Create confusion matrix using supervision\n",
        "            cm = sv.DetectionMetrics.ConfusionMatrix(classes=[0], iou_threshold=iou_thresh)\n",
        "\n",
        "            # Process test set\n",
        "            for img_path in test_images:\n",
        "                # Get ground truth\n",
        "                gt_boxes = get_ground_truth(img_path)\n",
        "\n",
        "                # Convert ground truth to supervision format\n",
        "                sv_gts = []\n",
        "                if gt_boxes:\n",
        "                    img = cv2.imread(str(img_path))\n",
        "                    h, w = img.shape[:2]\n",
        "                    for box in gt_boxes:\n",
        "                        x, y, w_box, h_box = box\n",
        "                        # Convert to xyxy format\n",
        "                        x1 = (x - w_box/2) * w\n",
        "                        y1 = (y - h_box/2) * h\n",
        "                        x2 = (x + w_box/2) * w\n",
        "                        y2 = (y + h_box/2) * h\n",
        "                        sv_gts.append(sv.DetectionPrediction(xyxy=np.array([x1, y1, x2, y2]), class_id=0, confidence=1.0))\n",
        "\n",
        "                # Get predictions\n",
        "                pred_results = model.predict(str(img_path), conf=conf_thresh)\n",
        "\n",
        "                # Convert predictions to supervision format\n",
        "                sv_preds = []\n",
        "                if len(pred_results[0].boxes) > 0:\n",
        "                    for i in range(len(pred_results[0].boxes.xyxy)):\n",
        "                        x1, y1, x2, y2 = pred_results[0].boxes.xyxy[i].tolist()\n",
        "                        conf = pred_results[0].boxes.conf[i].item()\n",
        "                        sv_preds.append(sv.DetectionPrediction(xyxy=np.array([x1, y1, x2, y2]), class_id=0, confidence=conf))\n",
        "\n",
        "                # Update confusion matrix\n",
        "                cm.update(preds=sv_preds, gts=sv_gts)\n",
        "\n",
        "            # Extract metrics from confusion matrix\n",
        "            matrix = cm.matrix()\n",
        "            tp = matrix[0, 0]\n",
        "            fp = matrix[0, 1]\n",
        "            fn = matrix[1, 0]\n",
        "\n",
        "            # Calculate metrics\n",
        "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "            # Store in matrices\n",
        "            precision_matrix[i, j] = precision\n",
        "            recall_matrix[i, j] = recall\n",
        "            f1_matrix[i, j] = f1\n",
        "\n",
        "    # Visualize results as heatmaps\n",
        "    metrics = {'Precision': precision_matrix, 'Recall': recall_matrix, 'F1 Score': f1_matrix}\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "    for i, (metric_name, matrix) in enumerate(metrics.items()):\n",
        "        im = axes[i].imshow(matrix, cmap='viridis', vmin=0, vmax=1)\n",
        "        axes[i].set_title(f'{metric_name} at Different Thresholds')\n",
        "        axes[i].set_xlabel('Confidence Threshold')\n",
        "        axes[i].set_ylabel('IoU Threshold')\n",
        "        axes[i].set_xticks(range(len(conf_thresholds)))\n",
        "        axes[i].set_yticks(range(len(iou_thresholds)))\n",
        "        axes[i].set_xticklabels(conf_thresholds)\n",
        "        axes[i].set_yticklabels(iou_thresholds)\n",
        "\n",
        "        # Add values in cells\n",
        "        for ii in range(len(iou_thresholds)):\n",
        "            for jj in range(len(conf_thresholds)):\n",
        "                axes[i].text(jj, ii, f'{matrix[ii, jj]:.2f}',\n",
        "                            ha=\"center\", va=\"center\", color=\"white\" if matrix[ii, jj] < 0.5 else \"black\")\n",
        "\n",
        "        fig.colorbar(im, ax=axes[i])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return precision_matrix, recall_matrix, f1_matrix\n",
        "\n",
        "# Execute the evaluation pipeline after training\n",
        "try:\n",
        "    # First train the model\n",
        "    print(\"Starting model training...\")\n",
        "\n",
        "    # After training completes\n",
        "    print(\"Evaluating model on test data...\")\n",
        "    calculate_map50()\n",
        "    create_metrics_table()\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "LlwHBPYu6lTt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}